{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm.auto import tqdm, trange\n",
    "import umap\n",
    "from sampler import ImbalancedDatasetSampler\n",
    "from ood_metrics import auroc, plot_roc, plot_barcode, calc_metrics, detection_error, fpr_at_95_tpr\n",
    "import mc_uncertainty as mc\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder, SVHN\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "FG_CLASSES = list(map(CIFAR10_CLASSES.index, \n",
    "                 [\"cat\"]))\n",
    "BG_CLASSES = list(map(CIFAR10_CLASSES.index, \n",
    "                 [\"airplane\", \"automobile\", \"bird\", \"deer\", \"frog\", \"dog\", \"horse\", \"ship\", \"truck\"]))\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "INPUT_SIZE = 224\n",
    "# INPUT_SIZE = 32\n",
    "BATCH_SIZE = 64\n",
    "NUM_FEATURE_LAYERS = 31\n",
    "\n",
    "RESULTS_FILE = 'cifar10_2class_polarity.h5'\n",
    "\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(kind='resnet152'):\n",
    "    # Download pretrained model\n",
    "    if kind == 'resnet152':\n",
    "        model = models.resnet152(pretrained=True)\n",
    "    elif kind == \"densenet161\":\n",
    "        model = models.densenet161(pretrained=True)\n",
    "    elif kind == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        \n",
    "    # Freeze weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Re-implement final classification layer\n",
    "    if kind == 'resnet152':\n",
    "        model.fc = nn.Linear(in_features=model.fc.in_features, out_features=NUM_CLASSES, bias=True)\n",
    "    elif kind == \"densenet161\":\n",
    "        model.classifier = nn.Linear(in_features=model.classifier.in_features, out_features=NUM_CLASSES, bias=True)\n",
    "    elif kind == \"vgg16\":\n",
    "        model.classifier[6] = nn.Linear(in_features=model.classifier[6].in_features, out_features=NUM_CLASSES, bias=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "            \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset.target_transform(dataset.targets[idx])\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "        \n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, lr_scheduler=None):\n",
    "    since = time.time()\n",
    "\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        tqdm.write('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        tqdm.write('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase], \n",
    "                                       total=len(dataloaders[phase]), \n",
    "                                       desc=\"{} batches\".format(phase),\n",
    "                                       leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            tqdm.write('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_loss = epoch_loss\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            elif phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(val_loss)\n",
    "            \n",
    "        tqdm.write(\"\\n\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history\n",
    "\n",
    "\n",
    "def save_model(model, path='model.pt'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "def plot_training_hist(train_hist, val_hist):\n",
    "    thist = []\n",
    "    vhist = []\n",
    "\n",
    "    thist = [h.cpu().numpy() for h in train_hist]\n",
    "    vhist = [h.cpu().numpy() for h in val_hist]\n",
    "\n",
    "    plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(range(1,NUM_EPOCHS+1),thist,label=\"Train\")\n",
    "    plt.plot(range(1,NUM_EPOCHS+1),vhist,label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def save_history(train_hist, val_hist, train_hist_path='train_hist.pickle', val_hist_path='val_hist.pickle'):\n",
    "    with open(train_hist_path, 'wb') as f:\n",
    "        pickle.dump(train_hist, f)\n",
    "    with open(val_hist_path, 'wb') as f:\n",
    "        pickle.dump(val_hist, f)\n",
    "        \n",
    "        \n",
    "def load_history(train_hist_path='train_hist.pickle', val_hist_path='val_hist.pickle'):\n",
    "    with open(train_hist_path, 'rb') as f:\n",
    "        train_hist = pickle.load(f)\n",
    "    with open(val_hist_path, 'rb') as f:\n",
    "        val_hist = pickle.load(f)\n",
    "    return train_hist, val_hist\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(dataloader, total=len(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    return accuracy.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a pretrained classifer and finetuning for CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the training data as follows:\n",
    "    - Remove all images with labels OOD_CLASSES\n",
    "    - Change the labels:\n",
    "        - 0: image is in FG_CLASSES (i.e it's a cat)\n",
    "        - 1: image is one of BG_CLASSES (i.e. it's a airplane, automobile, bird, deer, dog, or frog)\n",
    "        \n",
    "Transform the test data as follows:\n",
    "    - Change the labels:\n",
    "        - 0: image is in FG_CLASSES (i.e it's a cat)\n",
    "        - 1: image is one of BG_CLASSES (i.e. it's a airplane, automobile, bird, deer, dog, or frog)\n",
    "        - 2: image is one of OOD_CLASSES (i.e. it's a horse, ship, or truck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(INPUT_SIZE),\n",
    "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(INPUT_SIZE),\n",
    "        transforms.CenterCrop(INPUT_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "def label_transform(y):\n",
    "    if y in FG_CLASSES: return 0\n",
    "    elif y in BG_CLASSES: return 1\n",
    "    else: return 2\n",
    "\n",
    "cifar10_train = CIFAR10('/media/tadenoud/DATADisk/datasets/cifar10/', train=True, transform=data_transforms['train'], \n",
    "                        target_transform=label_transform)\n",
    "cifar10_train_no_aug = CIFAR10('/media/tadenoud/DATADisk/datasets/cifar10/', train=True, transform=data_transforms['val'],\n",
    "                               target_transform=label_transform)\n",
    "cifar10_test = CIFAR10('/media/tadenoud/DATADisk/datasets/cifar10/', train=False, transform=data_transforms['val'], \n",
    "                       target_transform=label_transform)\n",
    "cifar100_ood = CIFAR100('/media/tadenoud/DATADisk/datasets/cifar100/', train=False, transform=data_transforms['val'],\n",
    "                       target_transform=lambda y: y+NUM_CLASSES)\n",
    "imagenet_resize = ImageFolder('/media/tadenoud/DATADisk/datasets/tiny-imagenet-200/test', transform=data_transforms['val'],\n",
    "                             target_transform=lambda y: y+NUM_CLASSES)\n",
    "svhn_ood = SVHN('/media/tadenoud/DATADisk/datasets/svhn', split='test', transform=data_transforms['val'],\n",
    "                target_transform=lambda y: y+NUM_CLASSES)\n",
    "\n",
    "\n",
    "dataloaders_dict = {\n",
    "    'train': torch.utils.data.DataLoader(cifar10_train, batch_size=BATCH_SIZE, \n",
    "                                         sampler=ImbalancedDatasetSampler(cifar10_train),\n",
    "                                         num_workers=4, pin_memory=True),\n",
    "    'train_no_aug': torch.utils.data.DataLoader(cifar10_train_no_aug, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(cifar10_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    'ood': torch.utils.data.DataLoader(cifar100_ood, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    'imagenet_resize': torch.utils.data.DataLoader(imagenet_resize, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    'svhn': torch.utils.data.DataLoader(svhn_ood, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True),\n",
    "}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"vgg16\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimization objective, optimizer, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, beta=1, logits=False, reduce=True, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "    def fp(self, inputs, targets):\n",
    "        pl = inputs[:,targets].diag()\n",
    "        delta_p = torch.sub(inputs, pl.unsqueeze(dim=1))\n",
    "        return F.sigmoid(self.beta * (delta_p))\n",
    "        \n",
    "    def focal_loss(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, F.one_hot(targets, self.num_labels).float(), reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, F.one_hot(targets, self.num_labels).float(), reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        return self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        p_loss = self.fp(inputs, targets)\n",
    "        f_loss = self.focal_loss(inputs, targets)\n",
    "        loss = p_loss.mm(f_loss.transpose(0,1)).diag()\n",
    "        \n",
    "        if self.reduce:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler_ft = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience=5)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = PolarityLoss(alpha=0.25, gamma=2, beta=20, logits=True, reduce=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d287ff8dd5e044e4933d551d5952d837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=20, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0319 Acc: 0.7638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0190 Acc: 0.8653\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 1/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0286 Acc: 0.7869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0198 Acc: 0.8585\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 2/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0274 Acc: 0.7965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0172 Acc: 0.8762\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 3/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0269 Acc: 0.7978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0154 Acc: 0.8903\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 4/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0263 Acc: 0.8011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0142 Acc: 0.9009\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 5/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868324d347414f22877ac2faf680d777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0256 Acc: 0.8066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0128 Acc: 0.9106\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 11/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0254 Acc: 0.8069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8956\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 12/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ecd5e661654cf88d2f99c2e11059dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0150 Acc: 0.8918\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 18/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0245 Acc: 0.8148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0156 Acc: 0.8856\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 19/19\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22b53dafb634150809919e8dd087ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "if TRAIN:\n",
    "    # Train and evaluate\n",
    "    model, val_hist, train_hist = train_model(\n",
    "        model, \n",
    "        dataloaders_dict, \n",
    "        criterion, \n",
    "        optimizer_ft, \n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        lr_scheduler=scheduler_ft)\n",
    "    save_model(model, path='vgg16_polarity.pt')\n",
    "    save_history(train_hist, val_hist, 'train_hist_polarity.pickle', 'val_hist_polarity.pickle')\n",
    "else:\n",
    "    load_model(model, path='vgg16_polarity.pt')\n",
    "    train_hist, val_hist = load_history('train_hist_polarity.pickle', 'val_hist_polarity.pickle')\n",
    "\n",
    "plot_training_hist(train_hist, val_hist)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune top convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model)\n",
    "\n",
    "# Freeze weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Unfreeze top layers\n",
    "for param in model.features[23:].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.24.weight\n",
      "\t features.24.bias\n",
      "\t features.26.weight\n",
      "\t features.26.bias\n",
      "\t features.28.weight\n",
      "\t features.28.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "        \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0001, momentum=0.9)\n",
    "scheduler_ft = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience=5)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = PolarityLoss(alpha=0.25, gamma=2, beta=20, logits=True, reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a370a6ea6f459eaf420c62ac7cd6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=50, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 0/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tadenoud/anaconda3/envs/nn/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/tadenoud/anaconda3/envs/nn/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0243 Acc: 0.8166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0142 Acc: 0.8980\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 1/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0241 Acc: 0.8198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0148 Acc: 0.8928\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 2/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0242 Acc: 0.8171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0153 Acc: 0.8891\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 3/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0240 Acc: 0.8188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0150 Acc: 0.8924\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 4/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0237 Acc: 0.8224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0152 Acc: 0.8900\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 5/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0236 Acc: 0.8241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0147 Acc: 0.8946\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 6/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0234 Acc: 0.8250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0147 Acc: 0.8936\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 7/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0148 Acc: 0.8933\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 8/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0148 Acc: 0.8937\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 9/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0144 Acc: 0.8973\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 10/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0234 Acc: 0.8249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0145 Acc: 0.8962\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 11/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0231 Acc: 0.8270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8954\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 12/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0147 Acc: 0.8938\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 13/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0147 Acc: 0.8945\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 14/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 15/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0235 Acc: 0.8239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8949\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 16/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8949\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 17/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0236 Acc: 0.8219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8954\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 18/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0232 Acc: 0.8265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8949\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 19/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0234 Acc: 0.8234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8949\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 20/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0232 Acc: 0.8256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8949\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 21/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0234 Acc: 0.8233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 22/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 23/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 24/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0230 Acc: 0.8277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 25/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0233 Acc: 0.8250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 26/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train Loss: 0.0232 Acc: 0.8259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val batches', max=157, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "val Loss: 0.0146 Acc: 0.8948\n",
      "\r\n",
      "\n",
      "\r",
      "Epoch 27/49\n",
      "\r",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8730009675974e53bb9afee88d8dfa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train batches', max=782, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "if TRAIN:\n",
    "    # Train and evaluate\n",
    "    model, val_hist, train_hist = train_model(model, \n",
    "                                              dataloaders_dict, \n",
    "                                              criterion, \n",
    "                                              optimizer_ft, \n",
    "                                              num_epochs=NUM_EPOCHS,\n",
    "                                              lr_scheduler=scheduler_ft)\n",
    "    save_model(model, path='vgg16_fine_polarity.pt')\n",
    "    save_history(train_hist, val_hist, 'train_hist_fine_polarity.pickle', 'val_hist_fine_polarity.pickle')\n",
    "    \n",
    "else:\n",
    "    load_model(model, path='vgg16_fine_polarity.pt')\n",
    "    train_hist, val_hist = load_history('train_hist_fine_polarity.pickle', 'val_hist_fine_polarity.pickle')\n",
    "\n",
    "plot_training_hist(train_hist, val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model accuracy:\", evaluate_model(model, dataloaders_dict['val'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mahalanobis Distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penultimate_forward_vgg16(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    \n",
    "    # Break up self.classifier\n",
    "    penultimate = model.classifier[:5](x)\n",
    "    out = model.classifier[5:](penultimate)\n",
    "    return out, penultimate\n",
    "\n",
    "# Bind a function to the model to extract penultimate features\n",
    "model.penultimate_forward = penultimate_forward_vgg16.__get__(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader, feature_size, num_classes):\n",
    "    all_outputs = np.empty((0,num_classes))\n",
    "    all_features = np.empty((0,feature_size))\n",
    "    all_labels = np.empty(0)\n",
    "\n",
    "    model.eval()\n",
    "    for X, Y in tqdm(dataloader, total=len(dataloader)):\n",
    "        X = X.to(device)\n",
    "\n",
    "        outputs, features = model.penultimate_forward(X)\n",
    "\n",
    "        features = features.view((features.size(0), features.size(1), -1))\n",
    "        features = torch.mean(features, 2)\n",
    "\n",
    "        features = features.detach().cpu().numpy()\n",
    "\n",
    "        all_features = np.concatenate((all_features, features), axis=0)\n",
    "        all_outputs = np.concatenate((all_outputs, outputs.detach().cpu().numpy()), axis=0)\n",
    "        all_labels = np.concatenate((all_labels, Y.detach().cpu().numpy()), axis=0)\n",
    "        \n",
    "    return all_outputs, all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get penultimate features, outputs, and labels from datasets set\n",
    "if TRAIN:\n",
    "    model.eval()\n",
    "    \n",
    "    for dataset in ['train_no_aug', 'val', 'ood', 'svhn']:\n",
    "        softmax_outputs, mahalanobis_features, labels_out = extract_features(model, dataloaders_dict[dataset], feature_size=4096, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Save outputs to disk\n",
    "        with h5py.File(RESULTS_FILE, \"a\") as f:\n",
    "            if dataset in f.keys():\n",
    "                del f[dataset]\n",
    "                \n",
    "            g = f.create_group(dataset)\n",
    "            g.create_dataset(\"softmax_outputs\", data=softmax_outputs)\n",
    "            g.create_dataset(\"mahalanobis_features\", data=mahalanobis_features)\n",
    "            g.create_dataset(\"labels\", data=labels_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.covariance\n",
    "\n",
    "class Mahal_Dist(object):\n",
    "    def __init__(self, gt_features=None, gt_labels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if gt_features is not None and gt_labels is not None:\n",
    "            self.fit(gt_features, gt_labels)\n",
    "        \n",
    "    def fit(self, gt_features, gt_labels, num_classes):\n",
    "        \"\"\"Fit parameters used for Mahalanobis distance.\"\"\"\n",
    "        self.class_means = []\n",
    "        centered_features = gt_features.copy()\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            mask = gt_labels == i\n",
    "\n",
    "            # Calculate the class mean\n",
    "            self.class_means.append(gt_features[mask].mean(axis=0))\n",
    "\n",
    "            # Create mean subtracted features for covariance estimation\n",
    "            centered_features[mask] -= self.class_means[i]\n",
    "\n",
    "\n",
    "        # Calculate the inverted covariance matrix\n",
    "        group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "        group_lasso.fit(centered_features)\n",
    "        self.precision = group_lasso.precision_\n",
    "        self.covariance = group_lasso.covariance_\n",
    "\n",
    "        # Convert to pytorch tensors\n",
    "        self.class_means = torch.from_numpy(np.array(self.class_means)).float().to(device)\n",
    "        self.precision = torch.from_numpy(self.precision).float().to(device)\n",
    "        self.covariance = torch.from_numpy(self.covariance).float().to(device)\n",
    "        \n",
    "        \n",
    "    def __call__(self, features):\n",
    "        \"\"\"Return the distance based confidence score to each \n",
    "            of the means.\"\"\"\n",
    "        # Tile the features and means to vectorize the operation\n",
    "        num_means = self.class_means.shape[0]\n",
    "        num_feats = features.shape[0]\n",
    "\n",
    "        features = features.repeat(1, num_means).view(-1, features.shape[1])\n",
    "\n",
    "        # subtract means in batches\n",
    "        x = features - self.class_means.repeat(num_feats, 1)\n",
    "\n",
    "        # matmul, take diagonal, then reshape\n",
    "        dists = x.mm(self.precision).mm(x.transpose(0,1)).diag()\n",
    "        dists = dists.view(num_feats, num_means).transpose(0,1)\n",
    "\n",
    "        return dists\n",
    "    \n",
    "    \n",
    "    def label_dist(self, features):\n",
    "        \"\"\"Return the label of the closest mean and the \n",
    "            mahalanobis distance to it.\"\"\"\n",
    "        dists = self(features)\n",
    "        min_dists, labels = dists.min(dim=0)\n",
    "        return labels, min_dists \n",
    "    \n",
    "    \n",
    "    def save(self, fname='mahal_distance.h5'):\n",
    "        \"\"\"Save precomputed Mahal_Dist object with all means and covariance matrix.\"\"\"\n",
    "        with h5py.File(fname, 'a') as f:\n",
    "            # Remove old data if exists\n",
    "            if \"mahal_distance\" in f.keys():\n",
    "                del f['mahal_distance']\n",
    "                \n",
    "            # Store the new data\n",
    "            g = f.create_group(\"mahal_distance\")\n",
    "            g.create_dataset(\"means\", data=self.class_means.detach().cpu().numpy())\n",
    "            g.create_dataset(\"cov\", data=self.covariance.detach().cpu().numpy())\n",
    "            g.create_dataset(\"inv_cov\", data=self.precision.detach().cpu().numpy())\n",
    "           \n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, fname='mahal_distance.h5', device=torch.device(\"cpu\")):\n",
    "        \"\"\"Load precomputed Mahal_Dist object with all means and covariance matrix.\"\"\"\n",
    "        inst = cls()\n",
    "        \n",
    "        with h5py.File(fname, 'r') as f:\n",
    "            inst.class_means = torch.Tensor(f['mahal_distance/means'].value).to(device)\n",
    "            inst.covariance = torch.Tensor(f['mahal_distance/cov'].value).to(device)\n",
    "            inst.precision = torch.Tensor(f['mahal_distance/inv_cov'].value).to(device)\n",
    "        \n",
    "        return inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:  \n",
    "    with h5py.File(RESULTS_FILE, \"r\") as f:\n",
    "        mahalanobis_features_train = f['train_no_aug/mahalanobis_features'].value\n",
    "        labels_train = f['train_no_aug/labels'].value\n",
    "    \n",
    "    md = Mahal_Dist()\n",
    "    md.fit(mahalanobis_features_train, labels_train, num_classes=NUM_CLASSES)\n",
    "    md.save(RESULTS_FILE)\n",
    "else:\n",
    "    md = Mahal_Dist.load(RESULTS_FILE, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract FG, BG, OOD Softmax predictions and Mahal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "if TRAIN:\n",
    "    for dataset in ['val', 'ood', 'svhn']:\n",
    "        print(dataset)\n",
    "        with h5py.File(RESULTS_FILE, 'r') as f:\n",
    "            g = f[dataset]\n",
    "            labels = g['labels'][()]\n",
    "            features = g['mahalanobis_features'][()]\n",
    "            outputs = g['softmax_outputs'][()]    \n",
    "        \n",
    "        # Get predicted labels, distance to nearest mean\n",
    "        cur = 0\n",
    "        mahalanobis_labels = np.empty(0,)\n",
    "        mahalanobis_dists = np.empty(0,)\n",
    "        while cur < len(features):\n",
    "            l, d = md.label_dist(Tensor(features[cur:cur+BATCH_SIZE]).to(device))\n",
    "            mahalanobis_labels = np.concatenate((mahalanobis_labels, l.detach().cpu().numpy()), axis=0)\n",
    "            mahalanobis_dists = np.concatenate((mahalanobis_dists, d.detach().cpu().numpy()), axis=0)\n",
    "            cur += BATCH_SIZE\n",
    "        \n",
    "        with h5py.File(RESULTS_FILE, 'a') as f:\n",
    "            g = f[dataset]\n",
    "            if 'mahalanobis_labels' in g.keys():\n",
    "                del g['mahalanobis_labels']\n",
    "            g.create_dataset('mahalanobis_labels', data=mahalanobis_labels)\n",
    "            if 'mahalanobis_dists' in g.keys():\n",
    "                del g['mahalanobis_dists']\n",
    "            g.create_dataset('mahalanobis_dists', data=mahalanobis_dists)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(RESULTS_FILE, 'r') as f:\n",
    "    g = f['val']\n",
    "    labels_val = g['labels'][()]\n",
    "    mahalanobis_labels_val = g['mahalanobis_labels'][()]\n",
    "    mahalanobis_dist_val = g['mahalanobis_dists'][()]\n",
    "\n",
    "correct = np.sum((mahalanobis_labels_val == labels_val).astype(np.int))\n",
    "print(\"%d%% of val data classified correctly with mahalanobis distance\" % (correct / len(labels_val) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Mahalanobis to separate CIFAR10 and CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(RESULTS_FILE, \"r\") as f:\n",
    "    mahalanobis_dist_val = f['val/mahalanobis_dists'].value\n",
    "    print(mahalanobis_dist_val.shape)\n",
    "    labels_val = f['val/labels'].value\n",
    "\n",
    "    mahalanobis_dist_ood = f['ood/mahalanobis_dists'].value\n",
    "    print(mahalanobis_dist_ood.shape)\n",
    "    labels_ood = f['ood/labels'].value\n",
    "\n",
    "scores = np.concatenate((mahalanobis_dist_val, mahalanobis_dist_ood), axis=0)\n",
    "labels = np.concatenate((np.zeros(len(mahalanobis_dist_val)), np.ones(len(mahalanobis_dist_ood))), axis=0)\n",
    "\n",
    "plot_roc(scores, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "with h5py.File(RESULTS_FILE, 'r') as f:\n",
    "    features_train = f['train_no_aug/mahalanobis_features'].value\n",
    "    labels_train = f['train_no_aug/labels'].value\n",
    "    \n",
    "    features_val = f['val/mahalanobis_features'].value\n",
    "    labels_val = f['val/labels'].value + 2\n",
    "    \n",
    "    features_ood = f['ood/mahalanobis_features'].value\n",
    "    labels_ood = np.ones(len(features_ood)) * 4\n",
    "    \n",
    "features = np.concatenate((features_train, features_val, features_ood), axis=0)\n",
    "labels = np.concatenate((labels_train, labels_val, labels_ood), axis=0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = UMAP(n_neighbors=30).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Train data and Val data\")\n",
    "text_labels = ['FG_train', 'BG_train', 'FG_val', 'BG_val']\n",
    "\n",
    "for label in range(len(text_labels)):\n",
    "    x = embedding[:,0][labels == label]\n",
    "    y = embedding[:,1][labels == label]\n",
    "    ax.scatter(x, y, c=colors[label], s=5, label=text_labels[label], alpha=0.8, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Train data and Val data\")\n",
    "text_labels = ['FG_train', 'BG_train', 'OOD']\n",
    "\n",
    "for label in range(len(text_labels)):\n",
    "    legend_label = text_labels[label]\n",
    "    if legend_label == 'OOD':\n",
    "        label = 4\n",
    "    \n",
    "    x = embedding[:,0][labels == label]\n",
    "    y = embedding[:,1][labels == label]\n",
    "    ax.scatter(x, y, c=colors[label], s=5, label=legend_label, alpha=0.8, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible problem solutions\n",
    "\n",
    "- Cluster inlier classes used for Mahalanobis distance using GMM\n",
    "    - Problem: How many components? What form of covariance?\n",
    "    \n",
    "- Increase interclass distance in feature space using Polarity Loss\n",
    "\n",
    "- Buu provided paper on Neural Random Forest for OOD detection (https://openreview.net/forum?id=HygTE309t7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
